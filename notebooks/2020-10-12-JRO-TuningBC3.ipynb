{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<center><h1>Tuning Hyperparameters BC3 (Tag 2) </h1>\n",
    "John Ignacio R.M. 12 SPOOKY month 2020</center>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "Welcome to JupyROOT 6.20/04\n"
     ]
    }
   ],
   "source": [
    "#ada library\n",
    "ada_parent_dir = \"../\"\n",
    "import sys\n",
    "sys.path.append(ada_parent_dir)\n",
    "from ada2.data import read_dataset, split_dataset, all_hyperparams_comb\n",
    "from ada2.model import BinClassifModel3 as BC3\n",
    "from ada2.plot import plot_confidence_matrix\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#keras\n",
    "from keras.optimizers import adam, adadelta, adagrad, adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"../processed_data/xtohhOct2020\"\n",
    "bg = \"Xtohh_background\"\n",
    "seed = 420"
   ]
  },
  {
   "source": [
    "# Xtohh2000"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = \"Xtohh2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      EventWeight  label     m_FJpt   m_FJeta   m_FJphi      m_FJm     m_DTpt  \\\n",
       "0        0.001020      1  885.55927  0.104927 -2.448576  127604.30  623.22710   \n",
       "1        0.001117      1  855.69904  0.313113 -1.859287  122862.90  449.37933   \n",
       "2        0.000925      1  552.47845 -0.702952 -2.549875  109091.67  631.70496   \n",
       "3        0.001158      1  525.10590 -0.941433 -1.130162   82382.28  416.48105   \n",
       "4        0.001120      1  916.44147 -0.683193  1.804695  115936.01  677.16440   \n",
       "...           ...    ...        ...       ...       ...        ...        ...   \n",
       "8801     0.006433      0  402.06714  0.109710 -1.277847   68576.34  486.71262   \n",
       "8802     0.004849      0  542.29900  1.579771 -2.624035   84161.26  411.07132   \n",
       "8803     0.004849      0  548.63104 -0.033452  2.621298   79095.04  416.03915   \n",
       "8804     0.007816      0  683.98340 -0.029910 -0.760806  110728.80  609.47140   \n",
       "8805     0.004849      0  533.04846  0.334293  1.772496  172521.42  414.05844   \n",
       "\n",
       "       m_DTeta   m_DTphi       m_DTm  m_dPhiFTwDT  m_dRFJwDT  m_dPhiDTwMET  \\\n",
       "0    -0.731510  0.656939   85368.720     3.105514   3.216185     -0.192894   \n",
       "1    -0.306591  0.920655   55754.656     2.779941   2.848176     -0.019178   \n",
       "2     1.020756  0.610602   76213.550     3.122708   3.566858     -0.742126   \n",
       "3     0.103909  1.981465   58332.793     3.111627   3.282524     -0.130256   \n",
       "4    -0.495132 -1.274429   94135.960     3.079124   3.084862      0.416606   \n",
       "...        ...       ...         ...          ...        ...           ...   \n",
       "8801 -0.060529  1.469456  120999.410     2.747302   2.752572     -0.883233   \n",
       "8802  1.205967  0.438185   56194.777     3.062220   3.084951     -0.216563   \n",
       "8803  0.336025 -0.553298   70408.830     3.108589   3.130470     -0.352454   \n",
       "8804  0.094448  2.401307  148632.220     3.121072   3.123549      0.351719   \n",
       "8805 -1.568559 -1.097320   74110.530     2.869815   3.443354      0.771053   \n",
       "\n",
       "           m_MET       m_hhm    m_bbttpt  \n",
       "0     237.887240  1631.67020  263.697630  \n",
       "1     485.033330  1293.40280  463.512360  \n",
       "2     104.559220  1659.84830   80.008150  \n",
       "3     166.607220  1075.30920  109.524925  \n",
       "4     167.350300  1595.76110  244.283460  \n",
       "...          ...         ...         ...  \n",
       "8801   84.210686   891.92240  192.862270  \n",
       "8802   59.169407   970.41110  136.471160  \n",
       "8803   34.371227   983.20233  133.526060  \n",
       "8804   55.616740  1320.47700   75.680750  \n",
       "8805   29.818922  1424.76920  174.244190  \n",
       "\n",
       "[8806 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventWeight</th>\n      <th>label</th>\n      <th>m_FJpt</th>\n      <th>m_FJeta</th>\n      <th>m_FJphi</th>\n      <th>m_FJm</th>\n      <th>m_DTpt</th>\n      <th>m_DTeta</th>\n      <th>m_DTphi</th>\n      <th>m_DTm</th>\n      <th>m_dPhiFTwDT</th>\n      <th>m_dRFJwDT</th>\n      <th>m_dPhiDTwMET</th>\n      <th>m_MET</th>\n      <th>m_hhm</th>\n      <th>m_bbttpt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001020</td>\n      <td>1</td>\n      <td>885.55927</td>\n      <td>0.104927</td>\n      <td>-2.448576</td>\n      <td>127604.30</td>\n      <td>623.22710</td>\n      <td>-0.731510</td>\n      <td>0.656939</td>\n      <td>85368.720</td>\n      <td>3.105514</td>\n      <td>3.216185</td>\n      <td>-0.192894</td>\n      <td>237.887240</td>\n      <td>1631.67020</td>\n      <td>263.697630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001117</td>\n      <td>1</td>\n      <td>855.69904</td>\n      <td>0.313113</td>\n      <td>-1.859287</td>\n      <td>122862.90</td>\n      <td>449.37933</td>\n      <td>-0.306591</td>\n      <td>0.920655</td>\n      <td>55754.656</td>\n      <td>2.779941</td>\n      <td>2.848176</td>\n      <td>-0.019178</td>\n      <td>485.033330</td>\n      <td>1293.40280</td>\n      <td>463.512360</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000925</td>\n      <td>1</td>\n      <td>552.47845</td>\n      <td>-0.702952</td>\n      <td>-2.549875</td>\n      <td>109091.67</td>\n      <td>631.70496</td>\n      <td>1.020756</td>\n      <td>0.610602</td>\n      <td>76213.550</td>\n      <td>3.122708</td>\n      <td>3.566858</td>\n      <td>-0.742126</td>\n      <td>104.559220</td>\n      <td>1659.84830</td>\n      <td>80.008150</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001158</td>\n      <td>1</td>\n      <td>525.10590</td>\n      <td>-0.941433</td>\n      <td>-1.130162</td>\n      <td>82382.28</td>\n      <td>416.48105</td>\n      <td>0.103909</td>\n      <td>1.981465</td>\n      <td>58332.793</td>\n      <td>3.111627</td>\n      <td>3.282524</td>\n      <td>-0.130256</td>\n      <td>166.607220</td>\n      <td>1075.30920</td>\n      <td>109.524925</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001120</td>\n      <td>1</td>\n      <td>916.44147</td>\n      <td>-0.683193</td>\n      <td>1.804695</td>\n      <td>115936.01</td>\n      <td>677.16440</td>\n      <td>-0.495132</td>\n      <td>-1.274429</td>\n      <td>94135.960</td>\n      <td>3.079124</td>\n      <td>3.084862</td>\n      <td>0.416606</td>\n      <td>167.350300</td>\n      <td>1595.76110</td>\n      <td>244.283460</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8801</th>\n      <td>0.006433</td>\n      <td>0</td>\n      <td>402.06714</td>\n      <td>0.109710</td>\n      <td>-1.277847</td>\n      <td>68576.34</td>\n      <td>486.71262</td>\n      <td>-0.060529</td>\n      <td>1.469456</td>\n      <td>120999.410</td>\n      <td>2.747302</td>\n      <td>2.752572</td>\n      <td>-0.883233</td>\n      <td>84.210686</td>\n      <td>891.92240</td>\n      <td>192.862270</td>\n    </tr>\n    <tr>\n      <th>8802</th>\n      <td>0.004849</td>\n      <td>0</td>\n      <td>542.29900</td>\n      <td>1.579771</td>\n      <td>-2.624035</td>\n      <td>84161.26</td>\n      <td>411.07132</td>\n      <td>1.205967</td>\n      <td>0.438185</td>\n      <td>56194.777</td>\n      <td>3.062220</td>\n      <td>3.084951</td>\n      <td>-0.216563</td>\n      <td>59.169407</td>\n      <td>970.41110</td>\n      <td>136.471160</td>\n    </tr>\n    <tr>\n      <th>8803</th>\n      <td>0.004849</td>\n      <td>0</td>\n      <td>548.63104</td>\n      <td>-0.033452</td>\n      <td>2.621298</td>\n      <td>79095.04</td>\n      <td>416.03915</td>\n      <td>0.336025</td>\n      <td>-0.553298</td>\n      <td>70408.830</td>\n      <td>3.108589</td>\n      <td>3.130470</td>\n      <td>-0.352454</td>\n      <td>34.371227</td>\n      <td>983.20233</td>\n      <td>133.526060</td>\n    </tr>\n    <tr>\n      <th>8804</th>\n      <td>0.007816</td>\n      <td>0</td>\n      <td>683.98340</td>\n      <td>-0.029910</td>\n      <td>-0.760806</td>\n      <td>110728.80</td>\n      <td>609.47140</td>\n      <td>0.094448</td>\n      <td>2.401307</td>\n      <td>148632.220</td>\n      <td>3.121072</td>\n      <td>3.123549</td>\n      <td>0.351719</td>\n      <td>55.616740</td>\n      <td>1320.47700</td>\n      <td>75.680750</td>\n    </tr>\n    <tr>\n      <th>8805</th>\n      <td>0.004849</td>\n      <td>0</td>\n      <td>533.04846</td>\n      <td>0.334293</td>\n      <td>1.772496</td>\n      <td>172521.42</td>\n      <td>414.05844</td>\n      <td>-1.568559</td>\n      <td>-1.097320</td>\n      <td>74110.530</td>\n      <td>2.869815</td>\n      <td>3.443354</td>\n      <td>0.771053</td>\n      <td>29.818922</td>\n      <td>1424.76920</td>\n      <td>174.244190</td>\n    </tr>\n  </tbody>\n</table>\n<p>8806 rows Ã— 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Read xtohh dataset in SR tag 2\n",
    "df = read_dataset(source_path, signal, bg, \"SR\", 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "lrs = [5e-3, 1e-2, 5e-2, 1e-1]\n",
    "optis = [adam, adadelta, adagrad, adamax]\n",
    "activs = [\"relu\", \"softplus\"]\n",
    "\n",
    "splits = [\n",
    "    (0.6, 0.2, 0.2), (0.5, 0.3, 0.2), #80:20\n",
    "    (0.5, 0.2, 0.3), (0.4, 0.3, 0.3), #70:30\n",
    "    (0.4, 0.2, 0.4), (0.3, 0.3, 0.4), #60:40\n",
    "]\n",
    "\n",
    "sets = [split_dataset(df, *split, seed) for split in splits]\n",
    "ths = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "combs = [(sets[i], splits[i], lr, opti, acti) for i in range(len(splits))\n",
    "                                                        for lr in lrs\n",
    "                                                            for opti in optis\n",
    "                                                                for acti in activs]\n",
    "len(combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "uccesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 102: (0.4, 0.3, 0.3) 0.005 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 103: (0.4, 0.3, 0.3) 0.005 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 104: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 105: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 106: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 107: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 108: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 109: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 110: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 111: (0.4, 0.3, 0.3) 0.01 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 112: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 113: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 114: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 115: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 116: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 117: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 118: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 119: (0.4, 0.3, 0.3) 0.05 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 120: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 121: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 122: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 123: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 124: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 125: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 126: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 127: (0.4, 0.3, 0.3) 0.1 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 128: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 129: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 130: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 131: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 132: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 133: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 134: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 135: (0.4, 0.2, 0.4) 0.005 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 136: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 137: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 138: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 139: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 140: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 141: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 142: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 143: (0.4, 0.2, 0.4) 0.01 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 144: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 145: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 146: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 147: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 148: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 149: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 150: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 151: (0.4, 0.2, 0.4) 0.05 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 152: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 153: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 154: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 155: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 156: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 157: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 158: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 159: (0.4, 0.2, 0.4) 0.1 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 160: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 161: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 162: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 163: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 164: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 165: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 166: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 167: (0.3, 0.3, 0.4) 0.005 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 168: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 169: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 170: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 171: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 172: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 173: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 174: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 175: (0.3, 0.3, 0.4) 0.01 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 176: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 177: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 178: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 179: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 180: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 181: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 182: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 183: (0.3, 0.3, 0.4) 0.05 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 184: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adam'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 185: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adam'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 186: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adadelta'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 187: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adadelta'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 188: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adagrad'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 189: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adagrad'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 190: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adamax'> relu\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "Comb 191: (0.3, 0.3, 0.4) 0.1 <class 'keras.optimizers.Adamax'> softplus\n",
      "[ ] Training...\n",
      "[~] Succesful training\n",
      "[ ] Saving...\n",
      "[~] Succesful saving\n",
      "2020-10-12 17:39:02.337554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-12 17:39:02.351230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.351829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\n",
      "coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2020-10-12 17:39:02.351870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-10-12 17:39:02.351886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-12 17:39:02.356422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-12 17:39:02.357406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-12 17:39:02.358995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-12 17:39:02.359827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-12 17:39:02.359865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-12 17:39:02.359979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.361003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.361232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-10-12 17:39:02.361559: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-10-12 17:39:02.384291: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "2020-10-12 17:39:02.384532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5613ee5546f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-12 17:39:02.384550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-12 17:39:02.420058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.420408: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5613ee53f7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-12 17:39:02.420429: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 960M, Compute Capability 5.0\n",
      "2020-10-12 17:39:02.420638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.420892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0\n",
      "coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s\n",
      "2020-10-12 17:39:02.420940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-10-12 17:39:02.420957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-10-12 17:39:02.420990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-10-12 17:39:02.421012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-10-12 17:39:02.421031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-10-12 17:39:02.421051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-10-12 17:39:02.421066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-12 17:39:02.421151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.421429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.421634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-10-12 17:39:02.421689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-10-12 17:39:02.625165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-12 17:39:02.625209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-10-12 17:39:02.625218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-10-12 17:39:02.625423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.625709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-12 17:39:02.625924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1179 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)\n",
      "2020-10-12 17:39:28.763964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "f1_per_comb = all_hyperparams_comb(BC3, combs, ths, 50, \"../saved_models/tuningBC3xtohh2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 0         1      wavg\n",
       "comb th                               \n",
       "15   0.7  0.905108  0.980101  0.967347\n",
       "33   0.8  0.907760  0.979433  0.967243\n",
       "15   0.4  0.896739  0.979807  0.965680\n",
       "12   0.7  0.898666  0.979242  0.965539\n",
       "15   0.8  0.900563  0.978076  0.964894\n",
       "33   0.7  0.894431  0.978522  0.964220\n",
       "53   0.7  0.893378  0.978534  0.964051\n",
       "45   0.6  0.893929  0.978302  0.963952\n",
       "79   0.5  0.886781  0.978768  0.963867\n",
       "     0.6  0.887735  0.978449  0.963754\n",
       "7    0.7  0.894212  0.977895  0.963663\n",
       "93   0.5  0.886778  0.978405  0.963562\n",
       "76   0.4  0.885382  0.978516  0.963429\n",
       "15   0.5  0.889788  0.978307  0.963253\n",
       "53   0.8  0.892824  0.977563  0.963152"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>wavg</th>\n    </tr>\n    <tr>\n      <th>comb</th>\n      <th>th</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <th>0.7</th>\n      <td>0.905108</td>\n      <td>0.980101</td>\n      <td>0.967347</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <th>0.8</th>\n      <td>0.907760</td>\n      <td>0.979433</td>\n      <td>0.967243</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <th>0.4</th>\n      <td>0.896739</td>\n      <td>0.979807</td>\n      <td>0.965680</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <th>0.7</th>\n      <td>0.898666</td>\n      <td>0.979242</td>\n      <td>0.965539</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <th>0.8</th>\n      <td>0.900563</td>\n      <td>0.978076</td>\n      <td>0.964894</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <th>0.7</th>\n      <td>0.894431</td>\n      <td>0.978522</td>\n      <td>0.964220</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <th>0.7</th>\n      <td>0.893378</td>\n      <td>0.978534</td>\n      <td>0.964051</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <th>0.6</th>\n      <td>0.893929</td>\n      <td>0.978302</td>\n      <td>0.963952</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">79</th>\n      <th>0.5</th>\n      <td>0.886781</td>\n      <td>0.978768</td>\n      <td>0.963867</td>\n    </tr>\n    <tr>\n      <th>0.6</th>\n      <td>0.887735</td>\n      <td>0.978449</td>\n      <td>0.963754</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <th>0.7</th>\n      <td>0.894212</td>\n      <td>0.977895</td>\n      <td>0.963663</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <th>0.5</th>\n      <td>0.886778</td>\n      <td>0.978405</td>\n      <td>0.963562</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <th>0.4</th>\n      <td>0.885382</td>\n      <td>0.978516</td>\n      <td>0.963429</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <th>0.5</th>\n      <td>0.889788</td>\n      <td>0.978307</td>\n      <td>0.963253</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <th>0.8</th>\n      <td>0.892824</td>\n      <td>0.977563</td>\n      <td>0.963152</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "f1_per_comb.nlargest(15, [\"wavg\", 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((0.6, 0.2, 0.2), 0.01, keras.optimizers.Adamax, 'softplus')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "combs[15][1:]"
   ]
  }
 ]
}