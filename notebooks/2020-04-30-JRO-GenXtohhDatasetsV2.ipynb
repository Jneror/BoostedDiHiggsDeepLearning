{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating all Datasets for Xtohh signal (Last version)\n",
    "2020-04-30, John Rodriguez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New way of storing every dataset, based in the original approach of storing the signal and background together, with a column indicating if the event is signal or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/04\n"
     ]
    }
   ],
   "source": [
    "ada_parent_dir = \"../\"\n",
    "import sys\n",
    "sys.path.append(ada_parent_dir)\n",
    "import ada\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../raw_data\"\n",
    "prodata_path = \"../processed_data\"\n",
    "signal = \"Xtohh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moved to ada in 2020-04-30\n",
    "def gen_signal_datasets(signal, data_path, prodata_path):\n",
    "    #get roots\n",
    "    signal_roots = glob(f\"{data_path}/{signal}*.root\")\n",
    "    bg_roots = glob(f\"{data_path}/[!({signal})(data)]*.root\")\n",
    "    \n",
    "    #turn into dfs\n",
    "    signal_dfs = {signal_root.split('/')[-1][:-5]: ada.root_to_df(signal_root) for signal_root in signal_roots}\n",
    "    bg_dfs = [ada.root_to_df(bg_root) for bg_root in bg_roots]\n",
    "    \n",
    "    #join all backgrounds\n",
    "    bg_df = pd.concat(bg_dfs, axis = 0)\n",
    "    \n",
    "    #join background with the signals\n",
    "    datasets = {sign_name: pd.concat([sign_df, bg_df], axis = 0) for sign_name, sign_df in signal_dfs.items()}\n",
    "    \n",
    "    #save datasets into csvs\n",
    "    for signal_name, signal_df in datasets.items():\n",
    "        signal_df.to_csv(f\"{prodata_path}/{signal_name}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n",
      "ReadStreamerInfo, class:string, illegal uid=-2\n"
     ]
    }
   ],
   "source": [
    "ada.gen_signal_datasets(signal, data_path, prodata_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
